---
title: "ST405/ST645 Bayesian Data Analysis"
subtitle: "Assignment 1: "
author: "Prof. Niamh Cahill"
format: 
  html:
    embed-resources: true
    self-contained-math: true
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
```

## Instructions

Please submit your answers to this assignment by October 22nd, 4:00 PM. Ensure that all calculations are clearly shown, and include explanations where necessary. You may refer to the provided distribution information to help with your answers.

---


Suppose you are modeling lifetimes of components, where each lifetime is assumed to follow an **Exponential distribution** with rate parameter $\lambda$. That is, the density for a single observation $x_i$ is:


$$f(x_i \mid \lambda) = \lambda e^{-\lambda x_i}, \quad x_i > 0, \ \lambda > 0.$$


You wish to use Bayesian methods to estimate $\lambda$. As a prior, you use a $Gamma(\alpha, \beta)$ distribution for $\lambda$.

---

### Tasks

1. **Likelihood Function**
   Write down the likelihood function $L(\lambda \mid x_1, \dots, x_n)$ for the sample $x_1, \dots, x_n$ (up to proportionality).

2. **Appropriateness of Gamma Prior**
   Why is the Gamma distribution an appropriate prior for the rate parameter (\lambda) in this model?

3. **Determining Prior Hyperparameters**
   Suppose your prior belief is that the expected rate is about 0.2 units, with prior standard deviation of 2 units for the *rate parameter* $\lambda$. Find the values of $\alpha$ and $\beta$ for the Gamma prior that encode this belief.

4. **Posterior Distribution**
   Derive the posterior distribution for $\lambda$ given observations $x_1, \dots, x_n$.

5. **Posterior Mean Estimate**
   Suppose the observed data are $2.1, 0.9, 4.3, 3.7, 1.8$. Find the posterior mean estimate of $\lambda$.

6. **Conjugacy of the Prior**
   Is the Gamma distribution a conjugate prior for the exponential likelihood? Explain clearly.

7. **Comparing Posterior, Prior, and Data-Based Estimates**
   Compare the posterior mean estimate of (\lambda) to:

   * The prior mean, and
   * The maximum likelihood estimate (MLE) from the observed data.
     What insights do you gain from this comparison in terms of how Bayesian updating works?

---


### **Distribution Information**

-   You can use the following information about the Normal and Gamma distributions to help you with the question:

```{r, echo = FALSE}
library(knitr)

# Create the data for the table
data <- data.frame(
  `Probability Distribution` = c("Normal", "Gamma"),
  `PMF/PDF` = c(
    "$$\\frac{1}{\\sqrt{2\\pi} \\sigma} \\exp\\left(-\\frac{1}{2\\sigma^2}(x_i - \\mu)^2\\right)$$",
    "$$\\frac{b^a}{\\Gamma(a)}x^{a-1}e^{-b x},\\ x \\geq 0$$"
  ),
  `E(X)` = c(
    "$$\\mu$$",
    "$$\\frac{a}{b}$$"
  ),
  `Var(X)` = c(
    "$$\\sigma^2$$",
    "$$\\frac{a}{b^2}$$"
  )
)

# Render the table using knitr::kable
kable(data, col.names = c("Probability Distribution", "PMF/PDF", "E(X)", "Var(X)"), escape = FALSE)
```
